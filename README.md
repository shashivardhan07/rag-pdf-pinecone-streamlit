# ğŸ“„ RAG PDF Chatbot using Pinecone & Streamlit

A **Retrieval-Augmented Generation (RAG)** application that allows users to **upload PDF documents and ask questions** using a conversational interface.  
The system uses **vector search (Pinecone)** and **LLMs** to generate accurate, context-aware answers, all wrapped in an interactive **Streamlit UI**.

---

## ğŸš€ Features

- PDF-based question answering (RAG)
- Semantic search using Pinecone vector database
- LLM-powered answer generation
- Streamlit web interface
- Clean, modular, and production-ready structure
- Environment-based configuration (no hard-coded keys)

---

## ğŸ§  How It Works (RAG Pipeline)

1. Upload PDF document  
2. Extract and chunk text  
3. Generate embeddings for chunks  
4. Store embeddings in Pinecone  
5. Retrieve relevant chunks based on user query  
6. Generate answer using LLM + retrieved context  

This approach reduces hallucinations and improves answer accuracy.

---

## ğŸ“‚ Project Structure

<pre>
rag-pdf-pinecone-streamlit/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py              # Main Streamlit app
â”‚   â”œâ”€â”€ streamlit_app_voice.py        # Voice-based interaction (optional)
â”‚   â””â”€â”€ streamlit_app_translator.py   # Multilingual support (optional)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ RAG_GEMINI_PINECONE_PDF.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â””â”€â”€ .gitignore
</pre>

---

## ğŸ› ï¸ Tech Stack

- Python
- Streamlit
- LangChain
- Pinecone (Vector Database)
- Google Gemini / LLM APIs
- PDF Processing (PyPDF)
- dotenv

---

## âš™ï¸ Environment Variables

Create a `.env` file using the template below:

GEMINI_API_KEY=your_api_key_here

PINECONE_API_KEY=your_api_key_here

PINECONE_INDEX_NAME=your_index_name
